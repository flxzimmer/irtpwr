---
title: "Demo"
vignette: >
  %\VignetteIndexEntry{Demo}
  \usepackage[utf8]{inputenc}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
output: 
  rmarkdown::html_vignette:
    toc: true
---

```{r include=FALSE}
knitr::opts_chunk$set(eval=TRUE)
```

```{r message=FALSE}
library(pwrml)
library(mirt)
library(dplyr)
```


# Introduction

This vignette introduces the implementation of a power analysis for the Wald, LR, score and gradient test for linear hypothesis. It uses some IRT examples and treats basic as well as additional features of the package. It is directed towards beginner to intermediate level R users. Previous experience with the mirt package may be helpful. In the following we will cover the three-step workflow in detail:

* Setup Hypotheses (setup_hypothesis)
* Calculate Noncentrality Parameters (calculate_ncps)
* Calculate Power or Sample Size (power, ssize)

As additional features, we cover:

* Generate artificial datasets
* Performing hypothesis tests
* Estimating the time needed

Finally, we provide some additional models to facilitate adoption of the package for more complex hypotheses:

* 3PL model
* Multidimensional model


# Workflow example

We want to know the power and required sample size for a test of the Rasch vs 2PL model. We use the LSAT 7 Dataset from the mirt package.

As a first step, we load the dataset and fit a 2PL model.

```{r}
dat <- expand.table(LSAT7)
mirtfit <- mirt(dat,1,verbose = FALSE)
```

The 2PL parameters are then used as parameters for the alternative hypothesis in our hypothesis definition.
```{r}
hyp <- setup_hypothesis(type = "1PLvs2PL", altpars = mirtfit)
```

We can now calculate the noncentrality parameters.
```{r}
ncps <- calculate_ncps(hyp=hyp)
```

From the noncentrality parameters, we can estimate the power or required sample size.
```{r}
power(hyp=hyp,ncp=ncps,alpha=.05,ssize=500)
ssize(hyp=hyp,ncp=ncps,alpha=.05,power=.80)
```


# Functions in detail

We will present all included functions and their arguments in more detail.

## Setup Hypotheses (setup_hypothesis)

We can either use a fitted mirt model or specify alternative parameters directly. An example of the letter would be:

```{r}
altpars <- list(
        a = rlnorm(5,sdlog = .4),
        d = rnorm(5)
        )
altpars
hyp <- setup_hypothesis(type = "1PLvs2PL", altpars = altpars)

```

The following alternative hypotheses are currently implemented.

* Rasch against 2PL
* DIF in 2PL
* PCM against GPCM

The Rasch against 2PL hypothesis is presented above. The procedure for the DIF in 2PL hypothesis is analogous, yet is a bit more complicated since we need to define different groups:

```{r}
group1 = group2 <- list(
        a = rlnorm(5,sdlog = .2),
        d = rnorm(5)
        )

group2$a[1] = (group2$a[1])^2
group2$d[1] = group2$d[1] + .5

altpars <- list(group1,group2)

altpars

hyp <- setup_hypothesis(type = "DIF2PL", altpars = altpars)

```

To implement custom hypotheses, please refer to the respective vignette. Note that for both hypothesis types, we do not have to provide the parameters under the null hypothesis here, because they are implicitly defined by the hypotheses. The setup_hypothesis function, however, also takes a nullpars argument for cases in which the parmaters under the null hypothesis are not identified by the parameters under the alternative.


## Calculate Noncentrality Parameters (calculate_ncps)

The calculation of noncentrality parameters is straightforward. 
```{r}
ncps <- calculate_ncps(hyp=hyp)
```

To use the sampling-based parameters, one may use sampling=TRUE. The sample size of the sampling-based approach and the approximation of the Fisher expected matrix may be tweaked or left at their default values.

```{r}
ncps <- calculate_ncps(hyp=hyp,sampling=TRUE,sampling.npers = 10^4,approx.npers=10^4)
```


## Calculate Power or Sample Size (power, ssize)

The functions to calculate power and sample size are straightforward. One may use them to plot a power curve.
```{r}
n = seq(100,2000)
pow = power(hyp=hyp,ncp=ncps["Gradient"],alpha=.05,ssize=n)
plot(n,pow)
```



# Additional Features

We will take a look at some additional features.

## Generate artificial datasets

The hypothesis object can also be used to generate data according to the parameters of the alternative hypothesis. Note that setup.data also allows for non-normal person distributions, e.g. uniform or skewed-normal distributions.
```{r}
altpars <- list(
        a = rlnorm(5,sdlog = .4),
        d = rnorm(5)
        )

hyp <- setup_hypothesis(type = "1PLvs2PL", altpars = altpars)

data <- setup.data(hyp=hyp,n=500)
```


## Performing Hypothesis Tests

One can also perform hypothesis tests on observed data. This is done in two steps, model fitting (mml.fit) and calculation of the statitics (stat_obs). To fit both an unrestricted and restricted model in one go, we specify the data and the hypothesis.

```{r}
fitted <- mml.fit(data = data,hyp = hyp)
```

One may also use an approximation of the Fisher expected matrix, e.g. for larger item sets.
```{r}
fitted <- mml.fit(data = data,hyp = hyp,infmat.unres = "ApproxFisher",infmat.res="ApproxFisher",approx.npers = 10^4)
```

From the results, we can calculate the observed statistics and p-values.

```{r}
stats_obs <- stat_obs(fitted)
stats_obs
pvals <- pchisq(stats_obs,df=nrow(hyp$resmod$Amat),ncp=0,lower.tail=FALSE)
pvals
```


## Estimating the time needed for the analytical approach

We can calculate the approximate time needed to calculate the analytical noncentrality parameters using a larger numbers of items.

```{r}
altpars <- list(
        a = rlnorm(5,sdlog = .4),
        d = rnorm(5)
        )

hyp <- setup_hypothesis(type = "1PLvs2PL", altpars = altpars)

calctime(hyp,n.items=7)
```

Measuring the actual time for comparison:

```{r}
altpars <- list(
        a = rlnorm(7,sdlog = .4),
        d = rnorm(7)
        )

hyp <- setup_hypothesis(type = "1PLvs2PL", altpars = altpars)

calctime(hyp,n.items=7)

```

The suggested time does deviate sometimes from the actual time. As a result from our test runs, I suggest to expect +80% as a worst case scenario.



# Further Examples

To demonstrate extensability of the method to models not treated in the paper, we demonstrate testing some basic hypotheses in the 3PL model and a multidimensional model. We present only the sampling-based method here, but it can be extended to the analytical method in the future.


## 3PL model

We test the null hypothesis that the first item parameters are (1,0,.2) for the a,d, and g parameters respectively. The parameters under the alternative hypothesis are:

```{r}
altpars <- list(
  a = c(1.1,seq(.5,1.4,length.out=4)),
  d = c(.1,seq(1.3,-1.3,length.out=4)),
  g = c(.22,rep(.2,4))
)
altpars
```

Calculating sampling-based noncentrality parameters
```{r}
hyp <- setup_hypothesis(type = "3PL_basic", altpars = altpars)
set.seed(1)
ncps <- calculate_ncps(hyp=hyp,sampling=TRUE,sampling.npers = 10^5,approx.npers=10^5,SE.type="Fisher")
```

Power and sample size
```{r}
power(hyp=hyp,ncp=ncps,alpha=.05,ssize=500)
ssize(hyp=hyp,ncp=ncps,alpha=.05,power=.50)
```


## Multidimensional model

We test the null hypothesis that the difficulty of the first two item parameters is equal. The parameters under the alternative hypothesis are taken from the LSAT7 dataset:

```{r}
dat <- expand.table(LSAT7)
dat = dat[,c(2,4,1,3,5)] # re-ordering items, items 1 and 2 of the resulting data.frame are compared
model_an <- 'F1 = 1-5
      F2 = 1-4'
altpars = mirt(dat, model = mirt.model(model_an),verbose = FALSE)
coef(altpars,simplify=T)
```

Calculating sampling-based noncentrality parameters
```{r}
hyp <- setup_hypothesis(type = "multi_basic", altpars = altpars)
set.seed(1)
ncps <- calculate_ncps(hyp=hyp,sampling=TRUE,sampling.npers = 10^5,approx.npers=10^5)
```

Power and sample size
```{r}
power(hyp=hyp,ncp=ncps,alpha=.05,ssize=1000)
ssize(hyp=hyp,ncp=ncps,alpha=.05,power=.80)
```


